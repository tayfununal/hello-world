{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lesion_liver_config.ipynb",
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyOPjyJNaG7ACOIF/4SI+YUP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tayfununal/hello-world/blob/master/lesion_liver_config.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IK3eBy46hQi"
      },
      "source": [
        "!python --version"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Ti5gn9i6kRp"
      },
      "source": [
        "!git clone https://github.com/tayfununal/liverseg-2017-nipsws.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvpP2kRS6p0k"
      },
      "source": [
        "!pip install tensorflow==1.13.2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7yTDqwA6tua"
      },
      "source": [
        "!pip install scipy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2I4b_nj-h2q"
      },
      "source": [
        "!pip install Pillow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyBLWYLLBnoa"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "slim = tf.contrib.slim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpObw72Y7Sss"
      },
      "source": [
        "\"\"\"\n",
        "Original code from OSVOS (https://github.com/scaelles/OSVOS-TensorFlow)\n",
        "Sergi Caelles (scaelles@vision.ee.ethz.ch)\n",
        "\n",
        "Modified code for liver and lesion segmentation:\n",
        "Miriam Bellver (miriam.bellver@bsc.es)\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.contrib.layers.python.layers import utils\n",
        "\n",
        "import sys\n",
        "from datetime import datetime\n",
        "import os\n",
        "import scipy.misc\n",
        "from PIL import Image\n",
        "slim = tf.contrib.slim\n",
        "import scipy.io\n",
        "import timeit\n",
        "\n",
        "DTYPE = tf.float32\n",
        "\n",
        "\n",
        "def seg_lesion_arg_scope(weight_decay=0.0002):\n",
        "    \"\"\"Defines the arg scope.\n",
        "    Args:\n",
        "    weight_decay: The l2 regularization coefficient.\n",
        "    Returns:\n",
        "    An arg_scope.\n",
        "    \"\"\"\n",
        "    with slim.arg_scope([slim.conv2d, slim.convolution2d_transpose],\n",
        "                        activation_fn=tf.nn.relu,\n",
        "                        weights_initializer=tf.random_normal_initializer(stddev=0.001),\n",
        "                        weights_regularizer=slim.l2_regularizer(weight_decay),\n",
        "                        biases_initializer=tf.zeros_initializer,\n",
        "                        biases_regularizer=None,\n",
        "                        padding='SAME') as arg_sc:\n",
        "        return arg_sc\n",
        "\n",
        "\n",
        "def crop_features(feature, out_size):\n",
        "    \"\"\"Crop the center of a feature map\n",
        "    Args:\n",
        "    feature: Feature map to crop\n",
        "    out_size: Size of the output feature map\n",
        "    Returns:\n",
        "    Tensor that performs the cropping\n",
        "    \"\"\"\n",
        "    up_size = tf.shape(feature)\n",
        "    ini_w = tf.div(tf.subtract(up_size[1], out_size[1]), 2)\n",
        "    ini_h = tf.div(tf.subtract(up_size[2], out_size[2]), 2)\n",
        "    slice_input = tf.slice(feature, (0, ini_w, ini_h, 0), (-1, out_size[1], out_size[2], -1))\n",
        "    return tf.reshape(slice_input, [int(feature.get_shape()[0]), out_size[1], out_size[2], int(feature.get_shape()[3])])\n",
        "\n",
        "\n",
        "def _weight_variable(name, shape):\n",
        "    return tf.get_variable(name, shape, DTYPE, tf.truncated_normal_initializer(stddev=0.1))\n",
        "\n",
        "\n",
        "def _bias_variable(name, shape):\n",
        "    return tf.get_variable(name, shape, DTYPE, tf.constant_initializer(0.1, dtype=DTYPE))\n",
        "\n",
        "\n",
        "def seg_lesion(inputs, number_slices=1, volume=False, scope='seg_lesion'):\n",
        "    \"\"\"Defines the network\n",
        "    Args:\n",
        "    inputs: Tensorflow placeholder that contains the input image\n",
        "    scope: Scope name for the network\n",
        "    Returns:\n",
        "    net: Output Tensor of the network\n",
        "    end_points: Dictionary with all Tensors of the network\n",
        "    \"\"\"\n",
        "    im_size = tf.shape(inputs)\n",
        "\n",
        "    with tf.variable_scope(scope, 'seg_lesion', [inputs]) as sc:\n",
        "        end_points_collection = sc.name + '_end_points'\n",
        "        # Collect outputs of all intermediate layers.\n",
        "        with slim.arg_scope([slim.conv2d, slim.max_pool2d],\n",
        "                            padding='SAME',\n",
        "                            outputs_collections=end_points_collection):\n",
        "            net = slim.repeat(inputs, 2, slim.conv2d, 64, [3, 3], scope='conv1')\n",
        "            net = slim.max_pool2d(net, [2, 2], scope='pool1')\n",
        "            net_2 = slim.repeat(net, 2, slim.conv2d, 128, [3, 3], scope='conv2')\n",
        "            net = slim.max_pool2d(net_2, [2, 2], scope='pool2')\n",
        "            net_3 = slim.repeat(net, 3, slim.conv2d, 256, [3, 3], scope='conv3')\n",
        "            net = slim.max_pool2d(net_3, [2, 2], scope='pool3')\n",
        "            net_4 = slim.repeat(net, 3, slim.conv2d, 512, [3, 3], scope='conv4')\n",
        "            net = slim.max_pool2d(net_4, [2, 2], scope='pool4')\n",
        "            net_5 = slim.repeat(net, 3, slim.conv2d, 512, [3, 3], scope='conv5')\n",
        "\n",
        "            # Get side outputs of the network\n",
        "            with slim.arg_scope([slim.conv2d],\n",
        "                                activation_fn=None):\n",
        "                side_2 = slim.conv2d(net_2, 16, [3, 3], scope='conv2_2_16')\n",
        "                side_3 = slim.conv2d(net_3, 16, [3, 3], scope='conv3_3_16')\n",
        "                side_4 = slim.conv2d(net_4, 16, [3, 3], scope='conv4_3_16')\n",
        "                side_5 = slim.conv2d(net_5, 16, [3, 3], scope='conv5_3_16')\n",
        "\n",
        "                # Supervise side outputs\n",
        "                side_2_s = slim.conv2d(side_2, number_slices, [1, 1], scope='score-dsn_2')\n",
        "                side_3_s = slim.conv2d(side_3, number_slices, [1, 1], scope='score-dsn_3')\n",
        "                side_4_s = slim.conv2d(side_4, number_slices, [1, 1], scope='score-dsn_4')\n",
        "                side_5_s = slim.conv2d(side_5, number_slices, [1, 1], scope='score-dsn_5')\n",
        "                with slim.arg_scope([slim.convolution2d_transpose],\n",
        "                                    activation_fn=None, biases_initializer=None, padding='VALID',\n",
        "                                    outputs_collections=end_points_collection, trainable=False):\n",
        "                    side_2_s = slim.convolution2d_transpose(side_2_s, number_slices, 4, 2, scope='score-dsn_2-up')\n",
        "                    side_2_s = crop_features(side_2_s, im_size)\n",
        "                    utils.collect_named_outputs(end_points_collection, 'seg_lesion/score-dsn_2-cr', side_2_s)\n",
        "                    side_3_s = slim.convolution2d_transpose(side_3_s, number_slices, 8, 4, scope='score-dsn_3-up')\n",
        "                    side_3_s = crop_features(side_3_s, im_size)\n",
        "                    utils.collect_named_outputs(end_points_collection, 'seg_lesion/score-dsn_3-cr', side_3_s)\n",
        "                    side_4_s = slim.convolution2d_transpose(side_4_s, number_slices, 16, 8, scope='score-dsn_4-up')\n",
        "                    side_4_s = crop_features(side_4_s, im_size)\n",
        "                    utils.collect_named_outputs(end_points_collection, 'seg_lesion/score-dsn_4-cr', side_4_s)\n",
        "                    side_5_s = slim.convolution2d_transpose(side_5_s, number_slices, 32, 16, scope='score-dsn_5-up')\n",
        "                    side_5_s = crop_features(side_5_s, im_size)\n",
        "                    utils.collect_named_outputs(end_points_collection, 'seg_lesion/score-dsn_5-cr', side_5_s)\n",
        "\n",
        "                    # Main output\n",
        "                    side_2_f = slim.convolution2d_transpose(side_2, 16, 4, 2, scope='score-multi2-up')\n",
        "                    side_2_f = crop_features(side_2_f, im_size)\n",
        "                    utils.collect_named_outputs(end_points_collection, 'seg_lesion/side-multi2-cr', side_2_f)\n",
        "                    side_3_f = slim.convolution2d_transpose(side_3, 16, 8, 4, scope='score-multi3-up')\n",
        "                    side_3_f = crop_features(side_3_f, im_size)\n",
        "                    utils.collect_named_outputs(end_points_collection, 'seg_lesion/side-multi3-cr', side_3_f)\n",
        "                    side_4_f = slim.convolution2d_transpose(side_4, 16, 16, 8, scope='score-multi4-up')\n",
        "                    side_4_f = crop_features(side_4_f, im_size)\n",
        "                    utils.collect_named_outputs(end_points_collection, 'seg_lesion/side-multi4-cr', side_4_f)\n",
        "                    side_5_f = slim.convolution2d_transpose(side_5, 16, 32, 16, scope='score-multi5-up')\n",
        "                    side_5_f = crop_features(side_5_f, im_size)\n",
        "                    utils.collect_named_outputs(end_points_collection, 'seg_lesion/side-multi5-cr', side_5_f)\n",
        "                concat_side = tf.concat([side_2_f, side_3_f, side_4_f, side_5_f], 3)\n",
        "\n",
        "                net = slim.conv2d(concat_side, number_slices, [1, 1], scope='upscore-fuse')\n",
        "\n",
        "        end_points = slim.utils.convert_collection_to_dict(end_points_collection)\n",
        "        return net, end_points\n",
        "\n",
        "\n",
        "def upsample_filt(size):\n",
        "    factor = (size + 1) // 2\n",
        "    if size % 2 == 1:\n",
        "        center = factor - 1\n",
        "    else:\n",
        "        center = factor - 0.5\n",
        "    og = np.ogrid[:size, :size]\n",
        "    return (1 - abs(og[0] - center) / factor) * \\\n",
        "           (1 - abs(og[1] - center) / factor)\n",
        "\n",
        "\n",
        "# set parameters s.t. deconvolutional layers compute bilinear interpolation\n",
        "# N.B. this is for deconvolution without groups\n",
        "def interp_surgery(variables):\n",
        "    interp_tensors = []\n",
        "    for v in variables:\n",
        "        if '-up' in v.name:\n",
        "            h, w, k, m = v.get_shape()\n",
        "            tmp = np.zeros((m, k, h, w))\n",
        "            if m != k:\n",
        "                print 'input + output channels need to be the same'\n",
        "                raise\n",
        "            if h != w:\n",
        "                print 'filters need to be square'\n",
        "                raise\n",
        "            up_filter = upsample_filt(int(h))\n",
        "            tmp[range(m), range(k), :, :] = up_filter\n",
        "            interp_tensors.append(tf.assign(v, tmp.transpose((2, 3, 1, 0)), validate_shape=True, use_locking=True))\n",
        "    return interp_tensors\n",
        "\n",
        "\n",
        "def preprocess_img(image, number_slices):\n",
        "    \"\"\"Preprocess the image to adapt it to network requirements\n",
        "    Args:\n",
        "    Image we want to input the network (W,H,3) numpy array\n",
        "    Returns:\n",
        "\tImage ready to input the network (1,W,H,3)\n",
        "    \"\"\"\n",
        "    images = [[] for i in range(np.array(image).shape[0])]\n",
        "    \n",
        "    if number_slices > 2:\n",
        "        for j in range(np.array(image).shape[0]):\n",
        "            if type(image) is not np.ndarray:\n",
        "                for i in range(number_slices):\n",
        "                    images[j].append(np.array(scipy.io.loadmat(image[0][i])['section'], dtype=np.float32))\n",
        "            else:\n",
        "                img = image\n",
        "    else:\n",
        "        for j in range(np.array(image).shape[0]):\n",
        "            for i in range(3):\n",
        "                images[j].append(np.array(scipy.io.loadmat(image[0][0])['section'], dtype=np.float32))\n",
        "    in_ = np.array(images[0])\n",
        "    in_ = in_.transpose((1,2,0))\n",
        "    in_ = np.expand_dims(in_, axis=0)\n",
        "    return in_\n",
        "    \n",
        "\n",
        "def preprocess_labels(label, number_slices):\n",
        "    \"\"\"Preprocess the labels to adapt them to the loss computation requirements\n",
        "    Args:\n",
        "    Label corresponding to the input image (W,H) numpy array\n",
        "    Returns:\n",
        "    Label ready to compute the loss (1,W,H,1)\n",
        "    \"\"\"\n",
        "    labels = [[] for i in range(np.array(label).shape[0])]  \n",
        "    \n",
        "    for j in range(np.array(label).shape[0]):\n",
        "        if type(label) is not np.ndarray:\n",
        "            for i in range(number_slices):\n",
        "                labels[j].append(np.array(Image.open(label[0][i]), dtype=np.uint8))\n",
        "            \n",
        "    label = np.array(labels[0])\n",
        "    label = label.transpose((1,2,0))\n",
        "    max_mask = np.max(label) * 0.5\n",
        "    label = np.greater(label, max_mask)\n",
        "    label = np.expand_dims(label, axis=0)\n",
        "\n",
        "    return label\n",
        "\n",
        "\n",
        "def load_vgg_imagenet(ckpt_path, number_slices):\n",
        "    \"\"\"Initialize the network parameters from the VGG-16 pre-trained model provided by TF-SLIM\n",
        "    Args:\n",
        "    Path to the checkpoint\n",
        "    Returns:\n",
        "    Function that takes a session and initializes the network\n",
        "    \"\"\"\n",
        "    reader = tf.train.NewCheckpointReader(ckpt_path)\n",
        "    var_to_shape_map = reader.get_variable_to_shape_map()\n",
        "    vars_corresp = dict()\n",
        "    for v in var_to_shape_map:\n",
        "        if \"conv\" in v:\n",
        "            if not \"conv1/conv1_1/weights\" in v or number_slices<4:\n",
        "                vars_corresp[v] = slim.get_model_variables(v.replace(\"vgg_16\", \"seg_lesion\"))[0]\n",
        "    init_fn = slim.assign_from_checkpoint_fn(\n",
        "        ckpt_path,\n",
        "        vars_corresp)\n",
        "    return init_fn\n",
        "    \n",
        "\n",
        "def class_balanced_cross_entropy_loss(output, label, results_liver):\n",
        "    \"\"\"Define the class balanced cross entropy loss to train the network\n",
        "    Args:\n",
        "    output: Output of the network\n",
        "    label: Ground truth label\n",
        "    Returns:\n",
        "    Tensor that evaluates the loss\n",
        "   \n",
        "    \"\"\"\n",
        "\n",
        "    labels = tf.cast(tf.greater(label, 0.5), tf.float32)\n",
        "\n",
        "    output_gt_zero = tf.cast(tf.greater_equal(output, 0), tf.float32)\n",
        "    loss_val = tf.multiply(output, (labels - output_gt_zero)) - tf.log(\n",
        "        1 + tf.exp(output - 2 * tf.multiply(output, output_gt_zero)))\n",
        "    \n",
        "    loss_pos = tf.reduce_sum(-tf.multiply(results_liver, tf.multiply(labels, loss_val)))\n",
        "    loss_neg = tf.reduce_sum(-tf.multiply(results_liver, tf.multiply(1.0 - labels, loss_val)))\n",
        "        \n",
        "    final_loss = 0.1018*loss_neg + 0.8982*loss_pos\n",
        "    return final_loss\n",
        "\n",
        "\n",
        "def dice_coef_theoretical(y_pred, y_true):\n",
        "    \"\"\"Define the dice coefficient\n",
        "        Args:\n",
        "        y_pred: Prediction\n",
        "        y_true: Ground truth Label\n",
        "        Returns:\n",
        "        Dice coefficient\n",
        "        \"\"\"\n",
        "\n",
        "    y_true_f = tf.cast(tf.reshape(y_true, [-1]), tf.float32)\n",
        "    \n",
        "    y_pred_f = tf.nn.sigmoid(y_pred)\n",
        "    y_pred_f = tf.cast(tf.greater(y_pred_f, 0.5), tf.float32)\n",
        "    y_pred_f = tf.cast(tf.reshape(y_pred_f, [-1]), tf.float32)\n",
        "\n",
        "    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
        "    union = tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f)\n",
        "    dice = (2. * intersection) / (union + 0.00001)\n",
        "    \n",
        "    if (tf.reduce_sum(y_pred) == 0) and (tf.reduce_sum(y_true) == 0) :\n",
        "        dice = 1\n",
        "        \n",
        "    return dice\n",
        "\n",
        "\n",
        "def preprocess_results(label, number_slices):\n",
        "    \"\"\"Preprocess the labels to adapt them to the loss computation requirements\n",
        "    Args:\n",
        "    Label corresponding to the input image (W,H) numpy array\n",
        "    Returns:\n",
        "    Label ready to compute the loss (1,W,H,1)\n",
        "    \"\"\"\n",
        "    labels = [[] for i in range(np.array(label).shape[0])]  \n",
        "    \n",
        "    for j in range(np.array(label).shape[0]):\n",
        "        if type(label) is not np.ndarray:\n",
        "            for i in range(number_slices):\n",
        "                labels[j].append(np.array(Image.open(label[0][i]), dtype=np.uint8))\n",
        "            \n",
        "    # label = np.array(labels[0])\n",
        "    label = np.array(labels[0])\n",
        "    label = label.transpose((1,2,0))\n",
        "    # label = label[:, :, ::-1]\n",
        "    label = label/255.0\n",
        "    label = np.expand_dims(label, axis=0)\n",
        "\n",
        "    return label\n",
        "\n",
        "\n",
        "def parameter_lr():\n",
        "    \"\"\"Specify the learning rate for every parameter\n",
        "    Args:\n",
        "\n",
        "    Returns:\n",
        "    Dictionary with the learning rate for every parameter\n",
        "    \"\"\"\n",
        "\n",
        "    vars_corresp = dict()\n",
        "    vars_corresp['seg_lesion/conv1/conv1_1/weights'] = 1\n",
        "    vars_corresp['seg_lesion/conv1/conv1_1/biases'] = 2\n",
        "    vars_corresp['seg_lesion/conv1/conv1_2/weights'] = 1\n",
        "    vars_corresp['seg_lesion/conv1/conv1_2/biases'] = 2\n",
        "\n",
        "    vars_corresp['seg_lesion/conv2/conv2_1/weights'] = 1\n",
        "    vars_corresp['seg_lesion/conv2/conv2_1/biases'] = 2\n",
        "    vars_corresp['seg_lesion/conv2/conv2_2/weights'] = 1\n",
        "    vars_corresp['seg_lesion/conv2/conv2_2/biases'] = 2\n",
        "\n",
        "    vars_corresp['seg_lesion/conv3/conv3_1/weights'] = 1\n",
        "    vars_corresp['seg_lesion/conv3/conv3_1/biases'] = 2\n",
        "    vars_corresp['seg_lesion/conv3/conv3_2/weights'] = 1\n",
        "    vars_corresp['seg_lesion/conv3/conv3_2/biases'] = 2\n",
        "    vars_corresp['seg_lesion/conv3/conv3_3/weights'] = 1\n",
        "    vars_corresp['seg_lesion/conv3/conv3_3/biases'] = 2\n",
        "\n",
        "    vars_corresp['seg_lesion/conv4/conv4_1/weights'] = 1\n",
        "    vars_corresp['seg_lesion/conv4/conv4_1/biases'] = 2\n",
        "    vars_corresp['seg_lesion/conv4/conv4_2/weights'] = 1\n",
        "    vars_corresp['seg_lesion/conv4/conv4_2/biases'] = 2\n",
        "    vars_corresp['seg_lesion/conv4/conv4_3/weights'] = 1\n",
        "    vars_corresp['seg_lesion/conv4/conv4_3/biases'] = 2\n",
        "\n",
        "    vars_corresp['seg_lesion/conv5/conv5_1/weights'] = 1\n",
        "    vars_corresp['seg_lesion/conv5/conv5_1/biases'] = 2\n",
        "    vars_corresp['seg_lesion/conv5/conv5_2/weights'] = 1\n",
        "    vars_corresp['seg_lesion/conv5/conv5_2/biases'] = 2\n",
        "    vars_corresp['seg_lesion/conv5/conv5_3/weights'] = 1\n",
        "    vars_corresp['seg_lesion/conv5/conv5_3/biases'] = 2\n",
        "\n",
        "    vars_corresp['seg_lesion/conv2_2_16/weights'] = 1\n",
        "    vars_corresp['seg_lesion/conv2_2_16/biases'] = 2\n",
        "    vars_corresp['seg_lesion/conv3_3_16/weights'] = 1\n",
        "    vars_corresp['seg_lesion/conv3_3_16/biases'] = 2\n",
        "    vars_corresp['seg_lesion/conv4_3_16/weights'] = 1\n",
        "    vars_corresp['seg_lesion/conv4_3_16/biases'] = 2\n",
        "    vars_corresp['seg_lesion/conv5_3_16/weights'] = 1\n",
        "    vars_corresp['seg_lesion/conv5_3_16/biases'] = 2\n",
        "\n",
        "    vars_corresp['seg_lesion/score-dsn_2/weights'] = 0.1\n",
        "    vars_corresp['seg_lesion/score-dsn_2/biases'] = 0.2\n",
        "    vars_corresp['seg_lesion/score-dsn_3/weights'] = 0.1\n",
        "    vars_corresp['seg_lesion/score-dsn_3/biases'] = 0.2\n",
        "    vars_corresp['seg_lesion/score-dsn_4/weights'] = 0.1\n",
        "    vars_corresp['seg_lesion/score-dsn_4/biases'] = 0.2\n",
        "    vars_corresp['seg_lesion/score-dsn_5/weights'] = 0.1\n",
        "    vars_corresp['seg_lesion/score-dsn_5/biases'] = 0.2\n",
        "\n",
        "    vars_corresp['seg_lesion/upscore-fuse/weights'] = 0.01\n",
        "    vars_corresp['seg_lesion/upscore-fuse/biases'] = 0.02\n",
        "    return vars_corresp\n",
        "\n",
        "\n",
        "def _train(dataset, initial_ckpt, supervison, learning_rate, logs_path, max_training_iters, save_step, display_step,\n",
        "           global_step, number_slices=1, volume=False, iter_mean_grad=1, batch_size=1, task_id=1, loss=1, momentum=0.9, resume_training=False, config=None, finetune=1):\n",
        "    \"\"\"Train network\n",
        "    Args:\n",
        "    dataset: Reference to a Dataset object instance\n",
        "    initial_ckpt: Path to the checkpoint to initialize the network (May be parent network or pre-trained Imagenet)\n",
        "    supervison: Level of the side outputs supervision: 1-Strong 2-Weak 3-No supervision\n",
        "    learning_rate: Value for the learning rate. It can be number or an instance to a learning rate object.\n",
        "    logs_path: Path to store the checkpoints\n",
        "    max_training_iters: Number of training iterations\n",
        "    save_step: A checkpoint will be created every save_steps\n",
        "    display_step: Information of the training will be displayed every display_steps\n",
        "    global_step: Reference to a Variable that keeps track of the training steps\n",
        "    iter_mean_grad: Number of gradient computations that are average before updating the weights\n",
        "    batch_size:\n",
        "    momentum: Value of the momentum parameter for the Momentum optimizer\n",
        "    resume_training: Boolean to try to restore from a previous checkpoint (True) or not (False)\n",
        "    config: Reference to a Configuration object used in the creation of a Session\n",
        "    finetune: Use to select to select type of training, 0 for the parent network and 1 for finetunning\n",
        "    Returns:\n",
        "    \"\"\"\n",
        "    model_name = os.path.join(logs_path, \"seg_lesion.ckpt\")\n",
        "    if config is None:\n",
        "        config = tf.ConfigProto()\n",
        "        config.gpu_options.allow_growth = True\n",
        "        # config.log_device_placement = True\n",
        "        config.allow_soft_placement = True\n",
        "\n",
        "    tf.logging.set_verbosity(tf.logging.INFO)\n",
        "    \n",
        "    input_depth = 3\n",
        "    if number_slices > 3:\n",
        "        input_depth = number_slices\n",
        "    \n",
        "    # Prepare the input data\n",
        "    input_image = tf.placeholder(tf.float32, [batch_size, None, None, input_depth])\n",
        "    input_liver_results = tf.placeholder(tf.float32, [batch_size, None, None, number_slices])\n",
        "    input_label = tf.placeholder(tf.float32, [batch_size, None, None, number_slices])\n",
        "    beta = tf.placeholder(tf.float32, [batch_size])\n",
        "    gamma = tf.placeholder(tf.float32, [batch_size])\n",
        "    \n",
        "    # Create the network\n",
        "    with slim.arg_scope(seg_lesion_arg_scope()):\n",
        "        net, end_points = seg_lesion(input_image, number_slices, volume)\n",
        "\n",
        "    # Initialize weights from pre-trained model\n",
        "    if finetune == 0:\n",
        "        init_weights = load_vgg_imagenet(initial_ckpt, number_slices)\n",
        "\n",
        "    # Define loss\n",
        "    with tf.name_scope('losses'):\n",
        "        dsn_2_loss = class_balanced_cross_entropy_loss(end_points['seg_lesion/score-dsn_2-cr'], input_label, input_liver_results)\n",
        "        tf.summary.scalar('losses/dsn_2_loss', dsn_2_loss)\n",
        "        dsn_3_loss = class_balanced_cross_entropy_loss(end_points['seg_lesion/score-dsn_3-cr'], input_label, input_liver_results)\n",
        "        tf.summary.scalar('losses/dsn_3_loss', dsn_3_loss)\n",
        "        dsn_4_loss = class_balanced_cross_entropy_loss(end_points['seg_lesion/score-dsn_4-cr'], input_label, input_liver_results)\n",
        "        tf.summary.scalar('losses/dsn_4_loss', dsn_4_loss)\n",
        "        dsn_5_loss = class_balanced_cross_entropy_loss(end_points['seg_lesion/score-dsn_5-cr'], input_label, input_liver_results)\n",
        "        tf.summary.scalar('losses/dsn_5_loss', dsn_5_loss)\n",
        "\n",
        "        main_loss = class_balanced_cross_entropy_loss(net, input_label, input_liver_results)\n",
        "        tf.summary.scalar('losses/main_loss', main_loss)\n",
        "\n",
        "        if supervison == 1:\n",
        "            output_loss = dsn_2_loss + dsn_3_loss + dsn_4_loss + dsn_5_loss + main_loss\n",
        "        elif supervison == 2:\n",
        "            output_loss = 0.5*dsn_2_loss + 0.5*dsn_3_loss + 0.5*dsn_4_loss + 0.5*dsn_5_loss + main_loss\n",
        "        elif supervison == 3:\n",
        "            output_loss = main_loss\n",
        "        else:\n",
        "            sys.exit('Incorrect supervision id, select 1 for supervision of the side outputs, 2 for weak supervision '\n",
        "                     'of the side outputs and 3 for no supervision of the side outputs')\n",
        "        total_loss = output_loss+tf.add_n(tf.losses.get_regularization_losses())\n",
        "        tf.summary.scalar('losses/total_loss', total_loss)\n",
        "\n",
        "    # Define optimization method\n",
        "    with tf.name_scope('optimization'):\n",
        "        tf.summary.scalar('learning_rate', learning_rate)\n",
        "        optimizer = tf.train.MomentumOptimizer(learning_rate, momentum)\n",
        "        grads_and_vars = optimizer.compute_gradients(total_loss)\n",
        "        with tf.name_scope('grad_accumulator'):\n",
        "            grad_accumulator = []\n",
        "            for ind in range(0, len(grads_and_vars)):\n",
        "                if grads_and_vars[ind][0] is not None:\n",
        "                    grad_accumulator.append(tf.ConditionalAccumulator(grads_and_vars[0][0].dtype))\n",
        "        with tf.name_scope('apply_gradient'):\n",
        "            layer_lr = parameter_lr()\n",
        "            grad_accumulator_ops = []\n",
        "            for ind in range(0, len(grad_accumulator)):\n",
        "                if grads_and_vars[ind][0] is not None:\n",
        "                    var_name = str(grads_and_vars[ind][1].name).split(':')[0]\n",
        "                    var_grad = grads_and_vars[ind][0]\n",
        "                    grad_accumulator_ops.append(grad_accumulator[ind].apply_grad(var_grad*layer_lr[var_name],\n",
        "                                                                                 local_step=global_step))\n",
        "        with tf.name_scope('take_gradients'):\n",
        "            mean_grads_and_vars = []\n",
        "            for ind in range(0, len(grad_accumulator)):\n",
        "                if grads_and_vars[ind][0] is not None:\n",
        "                    mean_grads_and_vars.append((grad_accumulator[ind].take_grad(iter_mean_grad), grads_and_vars[ind][1]))\n",
        "            apply_gradient_op = optimizer.apply_gradients(mean_grads_and_vars, global_step=global_step)\n",
        "        # Log training info\n",
        "        \n",
        "    with tf.name_scope('metrics'):\n",
        "        dice_coef_op = dice_coef_theoretical(net, input_label)\n",
        "        tf.summary.scalar('metrics/dice_coeff', dice_coef_op)\n",
        "        \n",
        "    merged_summary_op = tf.summary.merge_all()\n",
        "\n",
        "    # Initialize variables\n",
        "    init = tf.global_variables_initializer()\n",
        "\n",
        "    with tf.Session(config=config) as sess:\n",
        "        print 'Init variable'\n",
        "        sess.run(init)\n",
        "\n",
        "        # op to write logs to Tensorboard\n",
        "        summary_writer = tf.summary.FileWriter(logs_path + '/train', graph=tf.get_default_graph())\n",
        "        test_writer = tf.summary.FileWriter(logs_path + '/test')\n",
        "\n",
        "        # Create saver to manage checkpoints\n",
        "        saver = tf.train.Saver(max_to_keep=None)\n",
        "\n",
        "        last_ckpt_path = tf.train.latest_checkpoint(logs_path)\n",
        "        if last_ckpt_path is not None and resume_training:\n",
        "            # Load last checkpoint\n",
        "            print('Initializing from previous checkpoint...')\n",
        "            saver.restore(sess, last_ckpt_path)\n",
        "            step = global_step.eval() + 1\n",
        "        else:\n",
        "            # Load pre-trained model\n",
        "            if finetune == 0:\n",
        "                print('Initializing from pre-trained imagenet model...')\n",
        "                init_weights(sess)\n",
        "            else:\n",
        "                print('Initializing from pre-trained model...')\n",
        "                # init_weights(sess)\n",
        "                var_list = []\n",
        "                for var in tf.global_variables():\n",
        "                    var_type = var.name.split('/')[-1]\n",
        "                    if 'weights' in var_type or 'bias' in var_type:\n",
        "                        var_list.append(var)\n",
        "                saver_res = tf.train.Saver(var_list=var_list)\n",
        "                saver_res.restore(sess, initial_ckpt)\n",
        "            step = 1\n",
        "        sess.run(interp_surgery(tf.global_variables()))\n",
        "        print('Weights initialized')\n",
        "\n",
        "        print 'Start training'\n",
        "        while step < max_training_iters + 1:\n",
        "            # Average the gradient\n",
        "            for iter_steps in range(0, iter_mean_grad):\n",
        "                batch_image, batch_label, batch_label_liver, batch_results_liver = dataset.next_batch(batch_size, 'train')\n",
        "                batch_image_val, batch_label_val, batch_label_liver_val, batch_results_liver_val = dataset.next_batch(batch_size, 'val')\n",
        "                image = preprocess_img(batch_image, number_slices)\n",
        "                val_image = preprocess_img(batch_image_val, number_slices)\n",
        "                liver_results = preprocess_results(batch_results_liver, number_slices)\n",
        "                liver_results_val = preprocess_results(batch_results_liver_val, number_slices)\n",
        "                if task_id == 2:\n",
        "                    batch_label = batch_label_liver\n",
        "                    batch_label_val = batch_label_liver_val\n",
        "\n",
        "                label = preprocess_labels(batch_label, number_slices)\n",
        "                label_val = preprocess_labels(batch_label_val, number_slices)\n",
        "\n",
        "                run_res = sess.run([total_loss, merged_summary_op, dice_coef_op] + grad_accumulator_ops, feed_dict={input_image: image, input_label: label, input_liver_results: liver_results})\n",
        "                batch_loss = run_res[0]\n",
        "                summary = run_res[1]\n",
        "                train_dice_coef = run_res[2]\n",
        "                if step % display_step == 0:\n",
        "                    val_run_res = sess.run([total_loss, merged_summary_op, dice_coef_op], feed_dict={input_image: val_image, input_label: label_val, input_liver_results: liver_results_val})\n",
        "                    val_batch_loss = val_run_res[0]\n",
        "                    val_summary = val_run_res[1]\n",
        "                    val_dice_coef = val_run_res[2]\n",
        "\n",
        "            # Apply the gradients\n",
        "            sess.run(apply_gradient_op)\n",
        "\n",
        "            # Save summary reports\n",
        "            summary_writer.add_summary(summary, step)\n",
        "            if step % display_step == 0:\n",
        "                test_writer.add_summary(val_summary, step)\n",
        "\n",
        "            # Display training status\n",
        "            if step % display_step == 0:\n",
        "                print >> sys.stderr, \"{} Iter {}: Training Loss = {:.4f}\".format(datetime.now(), step, batch_loss)\n",
        "                print >> sys.stderr, \"{} Iter {}: Validation Loss = {:.4f}\".format(datetime.now(), step, val_batch_loss)\n",
        "                print >> sys.stderr, \"{} Iter {}: Training Dice = {:.4f}\".format(datetime.now(), step, train_dice_coef)\n",
        "                print >> sys.stderr, \"{} Iter {}: Validation dice = {:.4f}\".format(datetime.now(), step, val_dice_coef)\n",
        "\n",
        "\n",
        "            # Save a checkpoint\n",
        "            if step % save_step == 0:\n",
        "                save_path = saver.save(sess, model_name, global_step=global_step)\n",
        "                print \"Model saved in file: %s\" % save_path\n",
        "            step += 1\n",
        "\n",
        "        if (step-1) % save_step != 0:\n",
        "            save_path = saver.save(sess, model_name, global_step=global_step)\n",
        "            print \"Model saved in file: %s\" % save_path\n",
        "\n",
        "        print('Finished training.')\n",
        "\n",
        "\n",
        "def train_seg(dataset, initial_ckpt, supervison, learning_rate, logs_path, max_training_iters, save_step,\n",
        "                 display_step, global_step, number_slices=1, volume=False, iter_mean_grad=1, batch_size=1, task_id=1,\n",
        "                 loss=1, momentum=0.9, resume_training=False, config=None):\n",
        "    \"\"\"Train parent network\n",
        "    Args:\n",
        "    See _train()\n",
        "    Returns:\n",
        "    \"\"\" \n",
        "    \n",
        "    _train(dataset, initial_ckpt, supervison, learning_rate, logs_path, max_training_iters, save_step, display_step,\n",
        "           global_step, number_slices, volume, iter_mean_grad, batch_size, task_id, loss, momentum, resume_training,\n",
        "           config, finetune=0)\n",
        "\n",
        "\n",
        "def test(dataset, checkpoint_path, result_path, number_slices=1, volume=False, config=None):\n",
        "    \"\"\"Test one sequence\n",
        "    Args:\n",
        "    dataset: Reference to a Dataset object instance\n",
        "    checkpoint_path: Path of the checkpoint to use for the evaluation\n",
        "    result_path: Path to save the output images\n",
        "    config: Reference to a Configuration object used in the creation of a Session\n",
        "    Returns:\n",
        "    net:\n",
        "    \"\"\"\n",
        "    if config is None:\n",
        "        config = tf.ConfigProto()\n",
        "        config.gpu_options.allow_growth = True\n",
        "        # config.log_device_placement = True\n",
        "        config.allow_soft_placement = True\n",
        "    tf.logging.set_verbosity(tf.logging.INFO)\n",
        "\n",
        "    # Input data\n",
        "    batch_size = 1\n",
        "    number_of_slices = number_slices\n",
        "    depth_input = number_of_slices\n",
        "    if number_of_slices < 3:\n",
        "        depth_input = 3\n",
        "        \n",
        "    input_image = tf.placeholder(tf.float32, [batch_size, None, None, depth_input])\n",
        "\n",
        "    # Create the cnn\n",
        "    with slim.arg_scope(seg_lesion_arg_scope()):\n",
        "        net, end_points = seg_lesion(input_image, number_slices, volume)\n",
        "    probabilities = tf.nn.sigmoid(net)\n",
        "    global_step = tf.Variable(0, name='global_step', trainable=False)\n",
        "\n",
        "    # Create a saver to load the network\n",
        "    saver = tf.train.Saver([v for v in tf.global_variables() if '-up' not in v.name and '-cr' not in v.name])\n",
        "    total_time = 0\n",
        "\n",
        "    with tf.Session(config=config) as sess:\n",
        "        sess.run(tf.global_variables_initializer())\n",
        "        sess.run(interp_surgery(tf.global_variables()))\n",
        "        saver.restore(sess, checkpoint_path)\n",
        "        if not os.path.exists(result_path):\n",
        "            os.makedirs(result_path)\n",
        "        for frame in range(0, dataset.get_test_size()):\n",
        "            img, curr_img = dataset.next_batch(batch_size, 'test')\n",
        "            curr_ct_scan = curr_img[0][0].split('/')[-2]\n",
        "            curr_frames = []\n",
        "            if 1:\n",
        "                for i in range(number_of_slices):\n",
        "                    curr_frames.append([curr_img[0][i].split('/')[-1].split('.')[0] + '.png'])\n",
        "                if not os.path.exists(os.path.join(result_path, curr_ct_scan)):\n",
        "                    os.makedirs(os.path.join(result_path, curr_ct_scan))\n",
        "                image = preprocess_img(curr_img, number_slices)\n",
        "                res = sess.run(probabilities, feed_dict={input_image: image})\n",
        "\n",
        "                res_np = res.astype(np.float32)[0, :, :, number_of_slices/2]\n",
        "\n",
        "                aux_var = curr_frames[number_of_slices/2][0]\n",
        "                scipy.misc.imsave(os.path.join(result_path, curr_ct_scan, aux_var), res_np)\n",
        "                print 'Saving ' + os.path.join(result_path, curr_ct_scan, aux_var)\n",
        "\n",
        "                for i in range(number_of_slices):\n",
        "                    aux_var = curr_frames[i][0]\n",
        "                    if not os.path.exists(os.path.join(result_path, curr_ct_scan, aux_var)):\n",
        "                        res_np = res.astype(np.float32)[0, :, :, i]\n",
        "                        scipy.misc.imsave(os.path.join(result_path, curr_ct_scan, aux_var), res_np)\n",
        "                        print 'Saving ' + os.path.join(result_path, curr_ct_scan, aux_var)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Nq8rajI8qem"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}